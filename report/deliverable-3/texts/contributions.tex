\section{Individual Contributions}
\subsection{Tom Harley}
\subsection{Josh Lee}
My main involvement thought-out this year has been my work on the database. This involved the setup, implementation and maintenance to add required features and to continuously integrate with the others in the group to provide a robust working system that satisfied all of the specification. I used Postgres and Sequelize as the foundation for the database as these were both reliable and extensive platforms with a-lot of additional support that helped me work with other members of my group. A big part of the database was implementing user and project based permissions that encompassed how users could interact with the database, I also worked with Hafeez in combining the permissions and the passport authorisation to guarantee the security of the server. The database also provided a file system that aided in storing and retrieving files and managing projects and folders.

Once the database was fully functional it was a case of implementing the file router to the specific defined protocol. This involved matching the request and response types for each request, error handling in the correct format and making sure that the expected functionality was being carried out each time. We used unit testing as much as possible throughout the process to implement this. My view on the project was that as a group we built an exceptional system that met all the basic functionality, also I felt we went beyond the scope, adding additional features where we felt necessary. We worked well with each other throughout the year adapting our meeting and sprint times to fit round each others work and deadlines to consistently work on the project right up until the final hand in.
\subsection{Calum Duff}
My most significant contribution to this project was the support of `Zeiss' files as a scalable image. I wrote all of the `C' code to interpret the binary file format data as described by the documention for the propriator file format. I then wrote all of the code to handle the extractor files, and grid them up onto a standard to be easily indexable. I also create an object used to efficiently map a request suited to the filetype to the actual image tile of interest.

I also wrote the code to parse and convert spreadsheet style content and serve as csv etc. There is also support for `Lecia' files in terms of image input and file creation, however there was not a chance to plumb this in to the endpoints.
In the beginning, I worked extensively with Yom to implement the database orm and initial endpoints. After the main bulk of the work for CZI pyramids was complete I then also worked extensively with Tom again to bug fix endpoints, connect my conversion modules to the main serving capabilities of the backend, and ensure basic comprehension of HCI/ML linking with our endpoints.

Overall I feel that there is a vast depth of work been completed in terms of the file conversion and specifically with CZI support, which achieves near perfect results and huge performance gains.
\subsection{Johannes Weck}
Throughout the development of our back-end server, I was responsible for thorough testing, which involved writing unit tests with mocha and chai, running integration tests through Postman as well as identifying and fixing bugs. One of the main challenges in this respect was understanding code written by other team-members. Clear and frequent communication between all members proved essential to this process.

During the last sprint I worked closely with Hafeez using pair-programming to resolve a range of issues flagged by the tests. Furthermore, I worked with Tom and Calum, finalizing server-side file-management. I was mostly involved with the file-system part of file storage, integrating the node-module `multer' with our server. `multer' was later swapped out for the package `body-parser' to allow compatibility with our assigned ML and HCI groups.
\subsection{Hafeez Abdul-Rehaman}
My role in the development of the server, involved producing the authentication system and providing security to each of the routes in the RESTful API. This was done through node.js libraries including \textit{passportjs} and \textit{jsonwebtokens}. I also tested the functionality of this after implementation to ensure it was working using tools such as Postman and curl. Whilst also conducting tests for authentication, I assisted Johannes in running and resolving test issues found in other parts of the implementation. By using more than one team member on larger tasks, it took less time to solve these problems. This took a considerable amount of time during the last sprint, as testing was required to be much larger and thorough for the fully implemented system. During the later sprints, I was also designated as scrum master. This meant I was responsible for organising tasks and managing time, and removing obstacles the team may face.

Another task that I completed was stress testing the final server. This involved using various tools to determine how well the server could handle certain scenarios. It also meant that I needed to create a virtual environment to conduct these tests. This was the most difficult part in the process, as certain packages and libraries were needed in order for it to function as expected.

As a team member, I did not feel that there were any major obstacles which impeded the development of the system. However, there were some issues regarding time and managing work set out by other modules within the Computer Science course. Some sprints clashed with other pieces of coursework that also needed to be completed. Therefore, additional care was needed when organising tasks related to the project and planning was required for an extended period of time which would overlap other upcoming coursework deadlines. This way as a team we could plan around other unrelated submissions.
